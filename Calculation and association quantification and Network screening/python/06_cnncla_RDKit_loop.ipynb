{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten,MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据\n",
    "drugRDKitMatrix = pd.read_csv(\"R_09_drugRDKitMatrix.csv\")\n",
    "TargetCount = pd.read_csv(\"R_09_TargetCount.csv\") \n",
    "durgTargetNum = pd.read_csv(\"R_09_durgTargetNum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_target(first_target):\n",
    "    durgTargetNum2 = durgTargetNum.copy()\n",
    "    durgTargetNum2['targetNum'] = np.where(durgTargetNum2['targetNum'] == first_target, 100, 0)\n",
    "    durgTargetNum2 = durgTargetNum2.drop_duplicates()\n",
    "    merged_df = pd.merge(durgTargetNum2, drugRDKitMatrix, on='ids', how='inner')  # 这里使用inner连接，你可以根据需要选择连接方式\n",
    "    merged_df = merged_df.dropna()\n",
    "    merged_df = merged_df.drop(merged_df.columns[0],axis=1)\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def get_input_gradients(input_data):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_data)\n",
    "        predictions = model(input_data)\n",
    "    gradients = tape.gradient(predictions, input_data)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochsNum=10\n",
    "file = open('06_cnncla_RDKit.txt', 'a', encoding=\"utf-8\")\n",
    "item = '\\t'.join([\"ID\",\"epochsNum\",\"acc_\",\"prec_\", \"reca_\", \"f1_\"])\n",
    "file.writelines(item + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in TargetCount['Var1'][1:3]:\n",
    "    print(target)\n",
    "    data = merged_target(target)\n",
    "    # 预处理\n",
    "    X = data.drop('targetNum', axis=1).values.astype(np.float32).reshape(-1, 27018,1)\n",
    "    y = data['targetNum'].values\n",
    "    y = to_categorical(y)\n",
    "    # 分割数据集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # 构建CNN神经网络\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=2, activation='relu', input_shape=(27018, 1)))\n",
    "    model.add(MaxPooling1D(pool_size =(20),padding ='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))  # 输出层数量 = 类别数\n",
    "    # 设置损失函数loss、优化器optimizer、准确性评价函数metrics\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # 训练模型\n",
    "    history = model.fit(X_train, y_train, validation_split=0.1, epochs=epochsNum)\n",
    "    #保存模型\n",
    "    modelName = '_'.join([\"06_cnncla_RDKit\",str(target),str(epochsNum), \"model.h5\"])\n",
    "    weightName = '_'.join([\"06_cnncla_RDKit\",str(target),str(epochsNum), \"weight.h5\"])\n",
    "\n",
    "    model.save(modelName)\n",
    "    model.save_weights(weightName)\n",
    "\n",
    "    # 测试集预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    # 混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    # 模型评价\n",
    "    acc_ = accuracy_score(y_true, y_pred_classes)\n",
    "    prec_ = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "    reca_ = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "    f1_ = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "    print('acc_, prec_, reca_, f1_:', acc_, prec_, reca_, f1_)\n",
    "    file = open('06_cnncla_RDKit.txt', 'a', encoding=\"utf-8\")\n",
    "    item = '\\t'.join([str(target),str(epochsNum),str(acc_),str(prec_),str(reca_), str(f1_)])\n",
    "    file.writelines(item + '\\n')\n",
    "    file.close()\n",
    "    sample_index = 0  # 选择第一个样本作为示例\n",
    "    x_sample = X_train[sample_index:sample_index+1]  # 选择一个样本并将其转换为二维数组，例如 (1, 27018, 1)\n",
    "    # 将示例输入数据转换为 TensorFlow Tensor\n",
    "    x_sample = tf.convert_to_tensor(x_sample, dtype=tf.float32)\n",
    "    # 计算输入数据的梯度\n",
    "    gradients = get_input_gradients(x_sample)\n",
    "    # 将梯度转换为Pandas DataFrame\n",
    "    gradient_df = pd.DataFrame({'Feature Index': range(len(gradients.numpy().flatten())),\n",
    "                                'Gradient': gradients.numpy().flatten()})\n",
    "    # 保存DataFrame到CSV文件\n",
    "    output_file = '_'.join([\"06_cnncla_RDKit\",str(target),str(epochsNum), \"gradients.csv\"])\n",
    "    gradient_df.to_csv(output_file, index=False)\n",
    "    # 可以根据梯度的大小来衡量输入数据的重要程度\n",
    "    # 例如，计算梯度的 L2 范数来表示重要程度\n",
    "    gradients_norm = np.linalg.norm(gradients.numpy(), axis=1)  # 计算每个特征的梯度 L2 范数\n",
    "    print(gradients_norm)\n",
    "\n",
    "\n",
    "    gradients_norm_df = pd.DataFrame({'Sample Index': range(len(gradients_norm)), 'Gradient Norm': gradients_norm.flatten()})\n",
    "\n",
    "    # 保存 DataFrame 到 CSV 文件\n",
    "    output_file2 = '_'.join([\"06_cnncla_RDKit\",str(target),str(epochsNum), \"gradients_norm_df.csv\"])\n",
    "    gradients_norm_df.to_csv(output_file2, index=False)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
